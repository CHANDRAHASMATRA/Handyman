{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial                  # used to setup connection between python and arduino\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import seaborn as sns\n",
    "x=[]            \n",
    "y=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]                     \n",
    "ar_data=serial.Serial(\"COM10\",250000) # getting data from arduino\n",
    "plt.ion()\n",
    "while True:\n",
    "    while (ar_data.inWaiting()==0):\n",
    "        pass\n",
    "    try:\n",
    "        ar_str=ar_data.readline() # reading data\n",
    "        data.append(float(ar_str)) # storing in a list\n",
    "        plt.cla()                 # following lines plots the data\n",
    "        plt.xlim(0,256)\n",
    "        plt.plot(data)\n",
    "        plt.show()\n",
    "        plt.pause(0.001)\n",
    "    except KeyboardInterrupt:   # stops plotting with keyboard interuption\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset to train classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain=np.linspace(0,100,100)          # initializing training data with fake inputs later we will update it.\n",
    "ar_data_train=serial.Serial(\"COM10\",250000) # getting data from arduino\n",
    "while True:\n",
    "    while (ar_data_train.inWaiting()==0): \n",
    "        pass\n",
    "    try:\n",
    "        ar_train_str=ar_data_train.readline() # reading data\n",
    "        datatrain=np.append(datatrain,float(ar_train_str)) #updating datatrain  \n",
    "        datatrain=np.delete(datatrain,[0]) \n",
    "        mfccs=librosa.feature.mfcc(datatrain,n_mfcc=13,sr=100) # we are taking 100 elements at a time and extracting 13 mfccs\n",
    "        x.append(mfccs)\n",
    "        y.append(1) # here value will be changed while training based on the present configuration of fingers 0 for all open 1 for all close.\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Pandas dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import *\n",
    "def array_list(array_num): \n",
    "    num_list = array_num.tolist() # list \n",
    "    return num_list\n",
    "finalx=[]\n",
    "n=0\n",
    "while n<=11403:    #iterating through whole data points \n",
    "    array_list(x[n])\n",
    "    l=[]\n",
    "    for i in x[n]:\n",
    "        l.append(i[0])  #making another list finalx so that we can use it to make pandas dataset.\n",
    "    finalx.append(l)\n",
    "    n=n+1\n",
    "\"\"\"The above lines of code makes list finalx from list x later from finalx we can create pandas dataset we can't\n",
    "use list x directly for creating data set because it's a list of lists\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(finalx) # creating pandas data set\n",
    "df[\"y\"]=y\n",
    "\n",
    "df.to_csv('D:\\MATRA\\CFI\\Handyman\\eeg_data_set1.csv') # saving .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=df.iloc[:,0:13]  #seperating input(MFCCs) from dataset.\n",
    "\n",
    "response=df.iloc[:,13]      #seperating output from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(predictors,response,test_size=0.2) # spitting dataset into training and testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel = Sequential()\n",
    "kerasmodel.add(Dense(13,input_dim=13,activation='relu')) #NN input layer one with 13 neurons since we have 13 MFCCs.\n",
    "kerasmodel.add(Dense(2,activation='relu'))               #Hidden Layer with 2 neuron using relu activation function\n",
    "kerasmodel.add(Dense(1,activation='sigmoid'))            #output layer with sigmod fucntion which return 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy']) #specifing loss function,optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel.fit(X_train,y_train,epochs=2000) #initiating training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,accuracy=kerasmodel.evaluate(X_test,y_test) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain=np.linspace(0,100,100)\n",
    "ar_data_test=serial.Serial(\"COM10\",250000,timeout=2)\n",
    "while True:\n",
    "    while (ar_data_train.inWaiting()==0):\n",
    "        pass\n",
    "    try:\n",
    "        ar_train_str=ar_data_test.readline()\n",
    "        datatrain=np.append(datatrain,float(ar_train_str))\n",
    "        datatrain=np.delete(datatrain,[0])\n",
    "        mfccs=librosa.feature.mfcc(datatrain,n_mfcc=13,sr=100)\n",
    "        lmfcc=[]\n",
    "        n=0\n",
    "        while n<=12:   \n",
    "            array_list(mfccs[n])\n",
    "            l=[]\n",
    "            for i in mfccs[n]:\n",
    "                l.append(i)\n",
    "                lmfcc.append(i)\n",
    "            n=n+1\n",
    "        test=pd.DataFrame(list([lmfcc])) \n",
    "        a=kerasmodel.predict_classes(test)\n",
    "        print(a[0][0])\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "        \n",
    "\"\"\"We have collected the data and trained a ML model, Now it’s time to test it in real time.\n",
    "We will start with connecting electrodes to scalp ,after running Arduino code in Arduino IDE\n",
    "we get the data through AD8232 ECG module to Arduino and Arduino sends data to serial ports \n",
    "where we use python to get data from these ports(line 2 in the code) . Later we read the data\n",
    "and extract MFCC using librosa and store MFCCs in list ‘mfcc’ after this we need make another\n",
    "list ‘lmfcc’ in order to create a pandas data set for testing. After creating pandas dataset \n",
    "we test this dataset with our saved ML model and print the final output i.e 0 or 1.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
